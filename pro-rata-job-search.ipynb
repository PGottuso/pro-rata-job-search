{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import os #used to navigate local machine to load email content\n",
    "from bs4 import BeautifulSoup #used to parse email structure\n",
    "import pandas as pd #used to organize and store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory location of Pro Rata email newsletters\n",
    "\n",
    "directory = \"C:\\\\my_directory\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute to list directory contents and verify you've selected the proper location\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate empty list to store results before passing back to master pandas dataframe\n",
    "\n",
    "row_list = []\n",
    "\n",
    "# define target keyword\n",
    "\n",
    "keyword = \"9A=91\"\n",
    "\n",
    "# for loop iterates through emails in the directory and uses BeautifulSoup to parse the content\n",
    "\n",
    "for m in range(len(os.listdir())):\n",
    "    f = open(os.listdir()[m], \"r\")\n",
    "    email = f.read()\n",
    "    soup = BeautifulSoup(email,\"lxml\")\n",
    "    \n",
    "    # once the content is parsed, look through each paragraph tag for the targeted content, then capture the company name and the description of the funding event\n",
    "    \n",
    "    for n in range(len(soup.find_all(\"p\"))):\n",
    "        if keyword in soup.find_all(\"p\")[n].text:\n",
    "            if n != 0: # ignores the first <p> tag since it always contains the entire email\n",
    "                if soup.find_all(\"p\")[n].strong != None: # company names are always bolded, so this ignores paragraphs not containing a non-bolded element\n",
    "                    name = soup.find_all(\"p\")[n].strong.text\n",
    "                    name = name.replace(\"=\\n\",\"\") # removes line breaks\n",
    "                    if name[0] == \"=\":\n",
    "                            name = name[name.find(\" \")+1:] # removes the leading bullet point or emoji, if present\n",
    "                    content = soup.find_all(\"p\")[n].text\n",
    "                    content = content[content.find(\" \")+1:] # removes the leading bullet point or emoji\n",
    "                    content = content.replace(\"=\\n\",\"\") # removes line breaks\n",
    "                    \n",
    "                    # after cleaning the name and content, insert into a dictionary, then add to the list\n",
    "                    \n",
    "                    dict1 = {\"name\":name,\"content\":content}\n",
    "                    row_list.append(dict1)   \n",
    "\n",
    "# convert the dictionary to a dataframe                    \n",
    "\n",
    "df = pd.DataFrame(row_list)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe to a csv file\n",
    "\n",
    "filename = \"your_file.csv\"\n",
    "\n",
    "df.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
